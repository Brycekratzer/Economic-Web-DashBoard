{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will develop the PatchTST model to predict S&P Close, Dow Jones Close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Congfiguration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will configure the PatchTST model based on the `Economic_Data_1994_2025` dataset we processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSTConfig, PatchTSTForPrediction, PatchTSTForPretraining\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For faster development\n",
    "device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/model_data/PostNorm_Full_Data.csv')\n",
    "dataset = dataset.drop(['DATE', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding PatchTST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Context Length**\n",
    "\n",
    "    Context length is how far we look back in total. If we were trying to predict the closing price for the SP500 tomorrow, our context length would be how far we look back to make our prediction.\n",
    "\n",
    "- **Patch Length**\n",
    "\n",
    "    Patch length is like a subset of our context length. When looking at our entire context length, patch length is the looking at each individual week up until tomorrow to make our final prediction\n",
    "\n",
    "- **Patch Stride**\n",
    "\n",
    "    Patch stride is how far our patch length will move after observing an individual week. We can overlap weeks to see any comparisons.\n",
    "    \n",
    "For each batch we will pass N amount of rows. Each row has previous rows (context length) attached to it. For each row & it's context length we pass it into our model to train on. During the training process we will used. masked forecasting. This will mask the last portion of our patch's for the model to predict. It then check's it's guesses and updates its weights accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreTraining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-training model will learn ***every*** column in our dataset from all dates. This will help the model develop relationships between all variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many features we are including \n",
    "NUM_INPUT = len(dataset.columns)\n",
    "\n",
    "# Batch size for training\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# For What we are predicting\n",
    "NUM_TARGET = 4\n",
    "\n",
    "# How many steps we take in the context length\n",
    "CONTEXT_LEN = 120\n",
    "\n",
    "# How many steps we take in the context length\n",
    "PATCH_LEN = 20\n",
    "\n",
    "# How far we move our patch length\n",
    "PATCH_STRD = 10\n",
    "\n",
    "# How our model is trained\n",
    "MASK_TYPE = 'forecast'\n",
    "\n",
    "# Dimension of the model's internal representations\n",
    "D_MODEL = 132\n",
    "\n",
    "# Number of transformer encoder layers (should be multiple of d_model)\n",
    "# When increased should increase path_dropout.\n",
    "# default: 3\n",
    "NUM_HIDD_LAYERS = 4\n",
    "\n",
    "# Number of parallel attention mechanisms, allows model to focus on different temporal patterns simultaneously (4-8) ideal range\n",
    "# should divide d model evenly \n",
    "#\n",
    "# larger d_model and more attention heads benefit from higher dropout rates\n",
    "# default: 4\n",
    "NUM_ATT_HEAD = 4\n",
    "\n",
    "# Prevent overfitting by randomly deactivating components, acts as regularization during training\n",
    "ATT_DROP = .13\n",
    "\n",
    "# Applies dropout to the feed-forward networks within transformer blocks, \n",
    "FF_DROP = .23\n",
    "\n",
    "# Randomly skips entire layers or sub-pathways during training\n",
    "# rule of thumb (num_hidden_layers - 2) * .05\n",
    "PATH_DROP = (NUM_HIDD_LAYERS - 2) * .05\n",
    "\n",
    "# How many items are masked in our forcast\n",
    "NUM_PATCH = int(PATCH_LEN * .3) # 30% of our Patch\n",
    "\n",
    "# Advance Configuring Model\n",
    "pretrain_config = PatchTSTConfig(\n",
    "    num_input_channels = NUM_INPUT,\n",
    "    context_length = CONTEXT_LEN,\n",
    "    patch_length = PATCH_LEN,\n",
    "    stride = PATCH_STRD,\n",
    "    mask_type='forecast',\n",
    "    num_forecast_mask_patches = NUM_PATCH,\n",
    "    do_mask_input=True,\n",
    "    d_model=D_MODEL,\n",
    "    num_hidden_layers=NUM_HIDD_LAYERS,\n",
    "    num_attention_heads=NUM_ATT_HEAD,\n",
    "    attention_dropout=ATT_DROP,\n",
    "    ff_dropout=FF_DROP,\n",
    "    path_dropout=PATH_DROP,\n",
    ")\n",
    "\n",
    "# Basic Configuration Model\n",
    "# pretrain_config = PatchTSTConfig(\n",
    "#     num_input_channels = NUM_INPUT,\n",
    "#     context_length = CONTEXT_LEN,\n",
    "#     patch_length = PATCH_LEN,\n",
    "#     stride = PATCH_STRD,\n",
    "#     mask_type='forecast',\n",
    "#     num_forecast_mask_patches = NUM_PATCH,\n",
    "#     do_mask_input=True,\n",
    "# )\n",
    "\n",
    "pretrain_model = PatchTSTForPretraining(pretrain_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting up our data into 2 portions. A `test` set and a `train` set. The test set is used to evalute our model based on training from the train set\n",
    "\n",
    "We split it 80/10/10, where 80% of our data is training data, and 10% of our data is testing, and 10% is validation for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constraints for development\n",
    "num_train = int(len(dataset) * .7)\n",
    "num_test = int(len(dataset) * .2)\n",
    "num_val = int(len(dataset) * .1)\n",
    "\n",
    "# Breaking up the data into train/test sets.\n",
    "train = dataset[0: num_train]\n",
    "test = dataset[num_train:num_test + num_train]\n",
    "val = dataset[num_test+num_train:(num_test+num_train) + num_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion here grabs context windows for all rows in our train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a context window for each data point to feed into the model during training\n",
    "def create_sequence_windows(data, window_size):\n",
    "    windows = []\n",
    "    \n",
    "    # We start in the dataFrame at an index 'window_size' and look back depending on the window size\n",
    "    # We will grab a context window for all data points\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        windows.append(data.iloc[i:i+window_size].values)\n",
    "    return np.array(windows)\n",
    "\n",
    "train_windows = create_sequence_windows(train, CONTEXT_LEN)\n",
    "test_windows = create_sequence_windows(test, CONTEXT_LEN)\n",
    "val_windows = create_sequence_windows(val, CONTEXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts our data in PyTorch tensors for proper data types during training\n",
    "past_values_train = torch.tensor(train_windows, dtype=torch.float32)\n",
    "past_values_test = torch.tensor(test_windows, dtype=torch.float32)\n",
    "past_values_val = torch.tensor(val_windows, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing our data to be passed into our model for pre training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the tensors in a dataset for the dataloader to properly use\n",
    "data_train = TensorDataset(past_values_train)\n",
    "\n",
    "# Divides our data into batches based on the BATCH_SIZE\n",
    "dataloader_train = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "data_test = TensorDataset(past_values_test)\n",
    "dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "data_val = TensorDataset(past_values_val)\n",
    "dataloader_val = DataLoader(data_val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = pretrain_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are training our model by doing the following:\n",
    "\n",
    "1. Divide Training into Epoch\n",
    "    - For each epoch we:\n",
    "        - Set model to train mode\n",
    "        - Pass in all of our data one batch size at a time\n",
    "        - After training on a patch we update our parameters\n",
    "        - Put our model into evaluation mode\n",
    "        - Test on our validation set and print results to output\n",
    "2. Final Train\n",
    "    - Once we pass through all epochs we do a final test on our\n",
    "        never seen data, `test` set. \n",
    "    - We iterate through our data one batch size at a time and evaluate the model\n",
    "        one last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 222/222 [02:29<00:00,  1.49it/s, loss=0.198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.2622819281443282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 26/26 [00:05<00:00,  5.15it/s, loss=0.0966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 0 : 0.13899239181325987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.12364005867962365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 26/26 [00:04<00:00,  5.84it/s, loss=0.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 1 : 0.10805232622302495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.0833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.09823174373590732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 26/26 [00:04<00:00,  5.85it/s, loss=0.064] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 2 : 0.07905014547017905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.0772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.08132501097547042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 26/26 [00:04<00:00,  5.83it/s, loss=0.0532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 3 : 0.06717115826904774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 222/222 [02:29<00:00,  1.48it/s, loss=0.0621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.07052316464617983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 26/26 [00:04<00:00,  5.80it/s, loss=0.0951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 4 : 0.07987813193064469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 222/222 [02:30<00:00,  1.48it/s, loss=0.0595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.06249091492311375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 26/26 [00:04<00:00,  5.83it/s, loss=0.0474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 5 : 0.05513558321847366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.0568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.05518483929336071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 26/26 [00:04<00:00,  5.79it/s, loss=0.0801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 6 : 0.06178715309271446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.0564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.04813969623599503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 26/26 [00:04<00:00,  5.80it/s, loss=0.0413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 7 : 0.043823727478201575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 222/222 [02:29<00:00,  1.49it/s, loss=0.0369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.04330549303542923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 26/26 [00:04<00:00,  5.80it/s, loss=0.0528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 8 : 0.04175261236154116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 222/222 [02:27<00:00,  1.50it/s, loss=0.0453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.03854264051292662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 26/26 [00:04<00:00,  5.79it/s, loss=0.0345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 9 : 0.03545231565546531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 222/222 [02:27<00:00,  1.50it/s, loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.03727998987242982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 26/26 [00:04<00:00,  5.82it/s, loss=0.0781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 10 : 0.05416582696712934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 222/222 [02:27<00:00,  1.50it/s, loss=0.0375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.03441753926443624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 26/26 [00:04<00:00,  5.81it/s, loss=0.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 11 : 0.04307905176224617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.0237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.03349779806359931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 26/26 [00:04<00:00,  5.76it/s, loss=0.0491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 12 : 0.03994049002917913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 222/222 [02:28<00:00,  1.49it/s, loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.03201975785867051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 26/26 [00:04<00:00,  5.79it/s, loss=0.0498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 13 : 0.04604765149549796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 222/222 [02:28<00:00,  1.50it/s, loss=0.03]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.0328673167271657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 26/26 [00:04<00:00,  5.84it/s, loss=0.0493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 14 : 0.04299611476464914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 59/59 [00:10<00:00,  5.46it/s, loss=0.0276]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for test set : 0.03824225911018202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(pretrain_model.parameters(), lr=.001)\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Allows for progress bar during training per epoch\n",
    "    loop = tqdm(dataloader_train, leave=True)\n",
    "    losses = []\n",
    "    \n",
    "    for batch in loop:\n",
    "        \n",
    "        # Puts model in train mode\n",
    "        pretrain_model.train()\n",
    "        \n",
    "        # Clears any previous gradient calculations\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Transfers batch onto GPU for faster processing\n",
    "        past_values = batch[0].to(device)\n",
    "        \n",
    "        # Foward pass through our model, generates predictions\n",
    "        outputs = pretrain_model(past_values=past_values)\n",
    "        \n",
    "        # Get's the loss for our predictions (how far off our predictions were)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Calculates which weights contributed to the error of our prediction\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(pretrain_model.parameters(), max_norm=3)\n",
    "        \n",
    "        # Updates the optimizer based on the calculations made from loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    print(\"Mean Training Loss\", np.mean(losses))\n",
    "        \n",
    "    pretrain_model.eval()\n",
    "    losses = []\n",
    "\n",
    "    loop = tqdm(dataloader_val, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        pretrain_model.eval()\n",
    "        \n",
    "        past_values = batch[0].to(device)\n",
    "        \n",
    "        outputs = pretrain_model(past_values=past_values)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(f\"Mean Training Loss for validation set on EPOCH {epoch} : {np.mean(losses)}\")\n",
    "\n",
    "pretrain_model.eval()\n",
    "losses = []\n",
    "\n",
    "loop = tqdm(dataloader_test, leave=True)\n",
    "\n",
    "for batch in loop:\n",
    "    \n",
    "    past_values = batch[0].to(device)\n",
    "    \n",
    "    outputs = pretrain_model(past_values=past_values)\n",
    "    \n",
    "    loss = outputs.loss\n",
    "    \n",
    "    loop.set_description(f'Test')\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "print(f\"Mean Training Loss for test set : {np.mean(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pretrain_model.state_dict(), 'pt_1*5yn_v2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: pt_1*5yn_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 15\n",
    "BATCH_SIZE = 16\n",
    "NUM_TARGET = 3\n",
    "CONTEXT_LEN = 150\n",
    "PATCH_LEN = 10\n",
    "PATCH_STRD = 5\n",
    "NUM_PATCH = int(PATCH_LEN * .4) # 40% of our Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Training Loss: 0.17927149336850434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: pt_1*5yn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many features we are including \n",
    "NUM_INPUT = len(dataset.columns)\n",
    "BATCH_SIZE = 16\n",
    "EPOCH = 15\n",
    "\n",
    "NUM_TARGET = 4\n",
    "CONTEXT_LEN = 120\n",
    "PATCH_LEN = 20\n",
    "PATCH_STRD = 10\n",
    "MASK_TYPE = 'forecast'\n",
    "D_MODEL = 132\n",
    "NUM_HIDD_LAYERS = 4\n",
    "NUM_ATT_HEAD = 4\n",
    "ATT_DROP = .13\n",
    "FF_DROP = .23\n",
    "PATH_DROP = (NUM_HIDD_LAYERS - 2) * .05\n",
    "NUM_PATCH = int(PATCH_LEN * .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Training Loss: 0.03824225911018202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT = 4\n",
    "NUM_TARGET = 4\n",
    "CONTEXT_LEN = 120\n",
    "PATCH_LEN = 20\n",
    "PATCH_STRD = 10\n",
    "MASK_TYPE = 'forecast'\n",
    "D_MODEL = 132\n",
    "NUM_HIDD_LAYERS = 4\n",
    "NUM_ATT_HEAD = 4\n",
    "ATT_DROP = .13\n",
    "FF_DROP = .23\n",
    "PATH_DROP = (NUM_HIDD_LAYERS - 2) * .05\n",
    "NUM_PATCH = int(PATCH_LEN * .3)\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `do_mask_input` parameter to False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many days to predict into the future\n",
    "PRED_LEN = 3 # One Month Prediction\n",
    "NUM_TARGET = 4\n",
    "\n",
    "# Advance Model Configuration \n",
    "ft_config = PatchTSTConfig(\n",
    "    num_input_channels = NUM_INPUT,\n",
    "    num_targets=NUM_TARGET,\n",
    "    context_length = CONTEXT_LEN,\n",
    "    patch_length = PATCH_LEN,\n",
    "    stride = PATCH_STRD,\n",
    "    mask_type='forecast',\n",
    "    num_forecast_mask_patches = NUM_PATCH,\n",
    "    do_mask_input=True,\n",
    "    d_model=D_MODEL,\n",
    "    num_hidden_layers=NUM_HIDD_LAYERS,\n",
    "    num_attention_heads=NUM_ATT_HEAD,\n",
    "    attention_dropout=ATT_DROP,\n",
    "    ff_dropout=FF_DROP,\n",
    "    path_dropout=PATH_DROP,\n",
    "    prediction_length=PRED_LEN\n",
    ")\n",
    "\n",
    "# # Basic Model Configuration \n",
    "# ft_config = PatchTSTConfig(\n",
    "#     num_input_channels = NUM_INPUT,\n",
    "#     num_targets=NUM_TARGET,\n",
    "#     context_length = CONTEXT_LEN,\n",
    "#     patch_length = PATCH_LEN,\n",
    "#     patch_stride = PATCH_STRD,\n",
    "#     prediction_length=PRED_LEN \n",
    "# )\n",
    "\n",
    "features_to_pred = ['^GSPC Close', '^DJI Close', 'ES=F Close', 'YM=F Close']\n",
    "\n",
    "ft_model = PatchTSTForPrediction(ft_config)\n",
    "\n",
    "# First, load your saved pretrained model\n",
    "pretrained_weights = torch.load('./pt_1*5yn_v2.bin')\n",
    "\n",
    "# Copy weights from the encoder part of the pretrained model\n",
    "# This will transfer only the compatible weights\n",
    "prediction_model_dict = ft_model.state_dict()\n",
    "\n",
    "for name, param in pretrained_weights.items():\n",
    "    if 'encoder' in name:\n",
    "        # The encoder part is usually named like 'encoder.xxx' in both models\n",
    "        if name in prediction_model_dict:\n",
    "            prediction_model_dict[name] = param\n",
    "ft_model.load_state_dict(prediction_model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constraints for development\n",
    "num_train = int(len(dataset) * .7)\n",
    "num_test = int(len(dataset) * .2)\n",
    "num_val = int(len(dataset) * .1)\n",
    "\n",
    "dataset = dataset[features_to_pred]\n",
    "targ_data = dataset\n",
    "\n",
    "train_targ = targ_data[0: num_train]\n",
    "train_feat = dataset[0: num_train]\n",
    "\n",
    "test_targ = targ_data[num_train:num_test + num_train]\n",
    "test_feat = dataset[num_train:num_test + num_train]\n",
    "\n",
    "val_targ = targ_data[num_test+num_train:(num_test+num_train) + num_val]\n",
    "val_feat = dataset[num_test+num_train:(num_test+num_train) + num_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Target/Input Features**\n",
    "\n",
    "This part is a little odd. \n",
    "\n",
    "- **Input Features**\n",
    "\n",
    "    To get the target features all we need to do is construct a window that looks at the past N amount of days for each data point.\n",
    "    We include the features we want to predict which makes it **Self Supervised**. \n",
    "\n",
    "- **Output Features**\n",
    "\n",
    "    What we are doing is getting the actual targets we want to predict and making a future window for just the 2 features. \n",
    "    In this case we are looking 90 days into the future, or what the model is predicting, and grabbing those values. This is used \n",
    "    for the model to evalute it's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a context window for each data point to feed into the model during training\n",
    "def create_sequence_windows(data, window_size):\n",
    "    windows = []\n",
    "    \n",
    "    # We start in the dataFrame at an index 'window_size' and look back depending on the window size\n",
    "    # We will grab a context window for all data points\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        windows.append(data.iloc[i:i+window_size].values)\n",
    "    return np.array(windows)\n",
    "\n",
    "train_feat_windows = create_sequence_windows(train_feat, CONTEXT_LEN)\n",
    "test_feat_windows = create_sequence_windows(test_feat, CONTEXT_LEN)\n",
    "val_feat_windows = create_sequence_windows(val_feat, CONTEXT_LEN)\n",
    "\n",
    "# Remove values at the end that don't have enough future data\n",
    "train_feat_windows = train_feat_windows[0:len(train_feat_windows) - PRED_LEN]\n",
    "test_feat_windows = test_feat_windows[0:len(test_feat_windows) - PRED_LEN]\n",
    "val_feat_windows = val_feat_windows[0:len(val_feat_windows) - PRED_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets indices for the target variables, starting from where we first start predicting with a full context length\n",
    "# to the last index that will allow for a full prediction\n",
    "train_targ_indices = range(CONTEXT_LEN, len(train_feat) - PRED_LEN + 1)\n",
    "test_targ_indices = range(CONTEXT_LEN, len(test_feat) - PRED_LEN + 1)\n",
    "val_targ_indices = range(CONTEXT_LEN, len(val_feat) - PRED_LEN + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targ_windows = [train_targ.iloc[i:i+PRED_LEN].values for i in train_targ_indices]\n",
    "test_targ_windows = [test_targ.iloc[i:i+PRED_LEN].values for i in test_targ_indices]\n",
    "val_targ_windows = [val_targ.iloc[i:i+PRED_LEN].values for i in val_targ_indices]\n",
    "\n",
    "train_targ_windows = np.array(train_targ_windows)\n",
    "test_targ_windows = np.array(test_targ_windows )\n",
    "val_targ_windows = np.array(val_targ_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([926, 120, 4]), torch.Size([926, 3, 4]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "past_train = torch.tensor(train_feat_windows, dtype=torch.float32)\n",
    "past_test = torch.tensor(test_feat_windows, dtype=torch.float32)\n",
    "past_val = torch.tensor(val_feat_windows, dtype=torch.float32)\n",
    "\n",
    "future_train = torch.tensor(train_targ_windows, dtype=torch.float32)\n",
    "future_test = torch.tensor(test_targ_windows, dtype=torch.float32)\n",
    "future_val = torch.tensor(val_targ_windows, dtype=torch.float32)\n",
    "past_test.shape, future_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(past_train, future_train)\n",
    "test_data = TensorDataset(past_test, future_test)\n",
    "val_data = TensorDataset(past_val, future_val)\n",
    "\n",
    "dataloader_train = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_val = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "ft_model = ft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/444 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 444/444 [00:24<00:00, 17.96it/s, loss=0.452] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.30278633377170777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 51/51 [00:00<00:00, 63.80it/s, loss=0.0642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 0 : 0.25489044569286645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 444/444 [00:22<00:00, 19.56it/s, loss=0.0492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.2569689399118091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 51/51 [00:00<00:00, 77.65it/s, loss=0.81]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 1 : 0.22454940732203277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 444/444 [00:22<00:00, 19.33it/s, loss=0.146] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.21865175764269387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 51/51 [00:00<00:00, 103.03it/s, loss=0.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 2 : 0.18072833193867816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 444/444 [00:25<00:00, 17.21it/s, loss=0.0594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.18823358548704433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 51/51 [00:00<00:00, 58.98it/s, loss=0.271] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 3 : 0.152521530056701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 444/444 [00:22<00:00, 19.81it/s, loss=0.0297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.16179026420823894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 51/51 [00:00<00:00, 61.47it/s, loss=0.249] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 4 : 0.13031085229971828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 444/444 [00:24<00:00, 18.50it/s, loss=0.394] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.14232880804008124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 51/51 [00:00<00:00, 105.83it/s, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 5 : 0.10975068438725144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 444/444 [00:23<00:00, 19.03it/s, loss=0.0886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.12557573129238375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 51/51 [00:00<00:00, 59.08it/s, loss=0.181] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 6 : 0.10203729675827074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 444/444 [00:22<00:00, 19.84it/s, loss=0.0666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.1140034791115705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 51/51 [00:00<00:00, 70.55it/s, loss=0.0546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 7 : 0.08896869935971849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 444/444 [00:24<00:00, 17.88it/s, loss=0.113]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.10526431913840005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 51/51 [00:00<00:00, 54.70it/s, loss=0.0822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 8 : 0.08209802013109713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 444/444 [00:23<00:00, 18.61it/s, loss=0.0217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss 0.09691613308061753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 51/51 [00:00<00:00, 106.38it/s, loss=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for validation set on EPOCH 9 : 0.07576879508355085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 116/116 [00:01<00:00, 81.17it/s, loss=0.101] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Loss for test set : 0.36414597441654395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(ft_model.parameters(), lr=.00001)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Allows for progress bar during training per epoch\n",
    "    loop = tqdm(dataloader_train, leave=True)\n",
    "    losses = []\n",
    "    \n",
    "    for past_values, future_values in loop:\n",
    "        ft_model.train()\n",
    "        \n",
    "        # Clears any previous gradient calculations\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Transfers batch onto GPU for faster processing\n",
    "        past_values = past_values.to(device)\n",
    "        future_values = future_values.to(device)\n",
    "        \n",
    "        # Foward pass through our model, generates predictions\n",
    "        outputs = ft_model(past_values=past_values, future_values=future_values)\n",
    "        \n",
    "        # Get's the loss for our predictions (how far off our predictions were)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Calculates which weights contributed to the error of our prediction\n",
    "        loss.backward()\n",
    "        \n",
    "        # Add gradient clipping to scale down calculated gradient\n",
    "        torch.nn.utils.clip_grad_norm_(ft_model.parameters(), max_norm=.0000001)\n",
    "        \n",
    "        # Updates the optimizer based on the calculations made from loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    print(\"Mean Training Loss\", np.nanmean(losses))\n",
    "        \n",
    "    ft_model.eval()\n",
    "    losses = []\n",
    "\n",
    "    loop = tqdm(dataloader_val, leave=True)\n",
    "    \n",
    "    for past_values, future_values in loop:\n",
    "        \n",
    "        past_values = past_values.to(device)\n",
    "        future_values = future_values.to(device)\n",
    "        \n",
    "        # Foward pass through our model, generates predictions\n",
    "        outputs = ft_model(past_values=past_values, future_values=future_values)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(f\"Mean Training Loss for validation set on EPOCH {epoch} : {np.nanmean(losses)}\")\n",
    "\n",
    "ft_model.eval()\n",
    "losses = []\n",
    "\n",
    "loop = tqdm(dataloader_test, leave=True)\n",
    "\n",
    "for past_values, future_values in loop:\n",
    "    \n",
    "    past_values = past_values.to(device)\n",
    "    future_values = future_values.to(device)\n",
    "    \n",
    "    # Foward pass through our model, generates predictions\n",
    "    outputs = ft_model(past_values=past_values, future_values=future_values)\n",
    "    \n",
    "    loss = outputs.loss\n",
    "    \n",
    "    loop.set_description(f'Test')\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "print(f\"Mean Training Loss for test set : {np.nanmean(losses)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ft_model.state_dict(), 'pt_1*5yn_v2_ft_3d_v1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pt_1*5yn_v1_ft_3d_v1** MSE - .11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model we will use a method called autoregression. Autoregression is where predictions are based on previous values of the target variable.\n",
    "\n",
    "The core idea of autoregression is as follows:\n",
    "\n",
    "1. The model makes an initial prediction\n",
    "\n",
    "2. We feed this prediction back into our dataset\n",
    "\n",
    "3. Based on our prediction and previous values, we make another prediction.\n",
    "\n",
    "What we are doing is creating a feedback loop where we keep making predictions based off prior predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def next_business_day(date):\n",
    "    # Add one day initially\n",
    "    next_date = date + timedelta(days=1)\n",
    "    \n",
    "    # Keep adding days until we reach a weekday (Monday-Friday)\n",
    "    while next_date.weekday() >= 5:  # 5 is Saturday, 6 is Sunday\n",
    "        next_date = next_date + timedelta(days=1)\n",
    "        \n",
    "    return next_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NUM = 4\n",
    "NUM_TARGET = 4\n",
    "CONTEXT_LEN = 120\n",
    "PATCH_LEN = 20\n",
    "PATCH_STRD = 10\n",
    "MASK_TYPE = 'forecast'\n",
    "D_MODEL = 132\n",
    "NUM_HIDD_LAYERS = 4\n",
    "NUM_ATT_HEAD = 4\n",
    "ATT_DROP = .13\n",
    "FF_DROP = .23\n",
    "PATH_DROP = (NUM_HIDD_LAYERS - 2) * .05\n",
    "NUM_PATCH = int(PATCH_LEN * .3)\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[1.0585, 1.2555, 1.0457, 1.2482]]]), scale=tensor([[[0.3332, 0.5114, 0.3324, 0.5149]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n",
      "PatchTSTForPredictionOutput(loss=None, prediction_outputs=tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]]), hidden_states=None, attentions=None, loc=tensor([[[nan, nan, nan, nan]]]), scale=tensor([[[nan, nan, nan, nan]]]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "features_to_pred = ['^GSPC Close', '^DJI Close', 'ES=F Close', 'YM=F Close']\n",
    "\n",
    "# How many days to predict into the future\n",
    "PRED_LEN = 3 # One Month Prediction\n",
    "\n",
    "# Advance Model Configuration \n",
    "ft_config = PatchTSTConfig(\n",
    "    num_input_channels = NUM_INPUT,\n",
    "    num_targets=NUM_TARGET,\n",
    "    context_length = CONTEXT_LEN,\n",
    "    patch_length = PATCH_LEN,\n",
    "    stride = PATCH_STRD,\n",
    "    d_model=D_MODEL,\n",
    "    num_hidden_layers=NUM_HIDD_LAYERS,\n",
    "    num_attention_heads=NUM_ATT_HEAD,\n",
    "    attention_dropout=ATT_DROP,\n",
    "    ff_dropout=FF_DROP,\n",
    "    path_dropout=PATH_DROP,\n",
    "    prediction_length=PRED_LEN \n",
    ")\n",
    "\n",
    "# Basic Model Configuration \n",
    "# ft_config = PatchTSTConfig(\n",
    "#     num_input_channels = NUM_INPUT,\n",
    "#     num_targets=NUM_TARGET,\n",
    "#     context_length = CONTEXT_LEN,\n",
    "#     patch_length = PATCH_LEN,\n",
    "#     patch_stride = PATCH_STRD,\n",
    "#     prediction_length=PRED_LEN \n",
    "# )\n",
    "\n",
    "ft_model = PatchTSTForPrediction(ft_config)\n",
    "PRIOR_DAYS = 50\n",
    "\n",
    "# Load in our model\n",
    "device = torch.device('mps')\n",
    "state_dict = torch.load('pt_1*5yn_v2_ft_3d_v1.bin')\n",
    "ft_model.load_state_dict(state_dict)\n",
    "\n",
    "# Get the normalized economic data\n",
    "pred_and_original_data = pd.read_csv('../data/model_data/PostNorm_Full_Data.csv')\n",
    "\n",
    "pred_and_original_data[0:len(pred_and_original_data)]\n",
    "\n",
    "# Filter out data to only contain features needed and Date for merging\n",
    "pred_and_original_data = pred_and_original_data[['DATE']+features_to_pred]\n",
    "pred_and_original_data_50_prior = pred_and_original_data[['DATE']+features_to_pred]\n",
    "\n",
    "pred_and_original_data_50_prior = pred_and_original_data_50_prior[0:len(pred_and_original_data_50_prior) - PRIOR_DAYS]\n",
    "\n",
    "# How many predictions we will recursively make\n",
    "NUM_ITER = 12\n",
    "\n",
    "\n",
    "# Autoregression\n",
    "for day in range(NUM_ITER):\n",
    "    \n",
    "    ft_model.eval()\n",
    "    \n",
    "    # Drop the date for prediction\n",
    "    df_copy = pred_and_original_data.drop(['DATE'], axis=1)\n",
    "    df_copy_50 = pred_and_original_data_50_prior.drop(['DATE'], axis=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Grab the last instance of CONTEXT_LEN days\n",
    "        features = df_copy.iloc[-CONTEXT_LEN:].values\n",
    "        features_50 = df_copy_50.iloc[-CONTEXT_LEN:].values\n",
    "        \n",
    "        # Convert to proper format for model\n",
    "        features = torch.tensor(features, dtype=torch.float32).unsqueeze(0)\n",
    "        features_50 = torch.tensor(features_50, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        predictions = ft_model(past_values=features)\n",
    "        print(predictions)\n",
    "        predictions_50 = ft_model(past_values=features_50)\n",
    "        \n",
    "        forcast = predictions.prediction_outputs\n",
    "        forcast_50 = predictions_50.prediction_outputs\n",
    "    \n",
    "    # Convert predictions back to prior format\n",
    "    predictions = forcast.squeeze(0).numpy()\n",
    "    predictions_50 = forcast_50.squeeze(0).numpy()\n",
    "    \n",
    "    pred_np = predictions\n",
    "    pred_np_50 = predictions_50\n",
    "    \n",
    "    # Get the last dates in the datasets\n",
    "    last_date = pd.to_datetime(pred_and_original_data['DATE']).iloc[-1]\n",
    "    last_date_50 = pd.to_datetime(pred_and_original_data_50_prior['DATE']).iloc[-1]\n",
    "\n",
    "    # Get the next business day after the last date\n",
    "    next_date = next_business_day(last_date)\n",
    "    next_date_50 = next_business_day(last_date_50)\n",
    "\n",
    "    if last_date.weekday() >= 5:\n",
    "        last_date = last_date + timedelta(days=1)\n",
    "        if last_date.weekday >= 5:\n",
    "            last_date = last_date + timedelta(days=1)\n",
    "            \n",
    "    if last_date_50.weekday() >= 5:\n",
    "        last_date_50 = last_date_50 + timedelta(days=1)\n",
    "        if last_date_50.weekday >= 5:\n",
    "            last_date_50 = last_date_50 + timedelta(days=1)\n",
    "\n",
    "    # Create date range for predictions\n",
    "    future_dates = pd.date_range(\n",
    "        start=last_date + timedelta(days=1),\n",
    "        periods=PRED_LEN,\n",
    "        freq='B'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    future_dates_50 = pd.date_range(\n",
    "        start=last_date_50 + timedelta(days=1),\n",
    "        periods=PRED_LEN,\n",
    "        freq='B'\n",
    "    )\n",
    "    \n",
    "    # Create a dataframe of our predictions with their corresponding dates\n",
    "    pred_df = pd.DataFrame(pred_np, columns=features_to_pred)\n",
    "    pred_df['DATE'] = future_dates\n",
    "    \n",
    "    pred_df_50 = pd.DataFrame(pred_np_50, columns=features_to_pred)\n",
    "    pred_df_50['DATE'] = future_dates_50\n",
    "\n",
    "    # Add predictions to dataset\n",
    "    pred_and_original_data = pd.concat([pred_and_original_data, pred_df], ignore_index=True)\n",
    "    pred_and_original_data['DATE'] = pd.to_datetime(pred_and_original_data['DATE'])\n",
    "    \n",
    "    pred_and_original_data_50_prior = pd.concat([pred_and_original_data_50_prior, pred_df_50], ignore_index=True)\n",
    "    pred_and_original_data_50_prior['DATE'] = pd.to_datetime(pred_and_original_data_50_prior['DATE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Predictions back to Base Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Load in unnormalized data and format to match features we are predicting\n",
    "original_df = pd.read_csv('../data/model_data/PreNorm_Full_Data.csv')\n",
    "original_df_50 = original_df[0:len(original_df) - PRIOR_DAYS]\n",
    "\n",
    "original_df = original_df[['DATE'] + features_to_pred]\n",
    "original_df['DATE'] = pd.to_datetime(original_df['DATE'])\n",
    "\n",
    "original_df_50 = original_df_50[['DATE'] + features_to_pred]\n",
    "original_df_50['DATE'] = pd.to_datetime(original_df_50['DATE'])\n",
    "\n",
    "WINDOW_SIZE = int(365*1.5) # Should be the same size from the one we used to normalize, REFER TO Gather_Historical_Data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5278/5278 [00:05<00:00, 998.26it/s] \n",
      "100%|██████████| 5228/5228 [00:06<00:00, 765.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def norm_data_st(norm_df, df, col, window_size=90):\n",
    "    denorm_df = norm_df.copy()\n",
    "\n",
    "    # Offset for getting the proper index for our normalized data\n",
    "    offset = window_size\n",
    "\n",
    "    # Moving through each row starting at \n",
    "    # window_size and going to df length\n",
    "    for i in tqdm(range(len(norm_df))):\n",
    "        original_id = i + offset\n",
    "        \n",
    "        window_start = original_id - window_size\n",
    "\n",
    "        # Grabs data from past\n",
    "        time_window = df.iloc[window_start:original_id]\n",
    "\n",
    "        # Grab current time\n",
    "        current_time = norm_df.iloc[i:i+1]\n",
    "\n",
    "        # Create scaler on based on window\n",
    "        robust_scaler = RobustScaler()\n",
    "        robust_scaler.fit(time_window[col])\n",
    "\n",
    "        # Apply scaler to current index feature\n",
    "        denomralized_values = robust_scaler.inverse_transform(current_time[col])\n",
    "        denorm_df.loc[norm_df.index[i], col] = denomralized_values[0]\n",
    "    return denorm_df\n",
    "\n",
    "# Get columns to normalize that doesn't include date.\n",
    "columns_to_unnormalize = pred_and_original_data.drop(['DATE'], axis=1).columns\n",
    "unnorm_df = norm_data_st(pred_and_original_data, original_df, columns_to_unnormalize,WINDOW_SIZE) \n",
    "unnorm_df_50 = norm_data_st(pred_and_original_data_50_prior, original_df_50, columns_to_unnormalize,WINDOW_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_time_frame_x2(year_start, year_end, df, x1, x2):\n",
    "    df_tf = df[(df['DATE'].dt.year >= year_start) & (df['DATE'].dt.year <= year_end)]\n",
    "\n",
    "    plt.plot(df_tf['DATE'], df_tf[x1], label=x1)\n",
    "    plt.plot(df_tf['DATE'], df_tf[x2], label=x2)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_time_frame_month(year_start, year_end, month_start, month_end, df1, df2, x1, x2):\n",
    "    df_tf1 = df1[(df1['DATE'].dt.year >= year_start) & (df1['DATE'].dt.year <= year_end)]\n",
    "    df_tf1 = df_tf1[(df_tf1['DATE'].dt.month >= month_start) & (df_tf1['DATE'].dt.month <= month_end)]\n",
    "    \n",
    "    df_tf2 = df2[(df2['DATE'].dt.year >= year_start) & (df2['DATE'].dt.year <= year_end)]\n",
    "    df_tf2 = df_tf2[(df_tf2['DATE'].dt.month >= month_start) & (df_tf2['DATE'].dt.month <= month_end)]\n",
    "    \n",
    "    plt.plot(df_tf2['DATE'], df_tf2[x1], label=f'{x1} Projection', linestyle='--')\n",
    "    plt.plot(df_tf2['DATE'], df_tf2[x2], label=f'{x2} Projection', linestyle='--')\n",
    "    \n",
    "    plt.plot(df_tf1['DATE'], df_tf1[x1], label=x1)\n",
    "    plt.plot(df_tf1['DATE'], df_tf1[x2], label=x2)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set a tick for every day\n",
    "    # plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    # plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()  # This helps prevent the rotated labels from being cut off\n",
    "    plt.show()\n",
    "    \n",
    "def plot_time_frame_year(year_start, year_end, df1, df2, x1, x2):\n",
    "    df_tf1 = df1[(df1['DATE'].dt.year >= year_start) & (df1['DATE'].dt.year <= year_end)]\n",
    "    \n",
    "    df_tf2 = df2[(df2['DATE'].dt.year >= year_start) & (df2['DATE'].dt.year <= year_end)]\n",
    "    \n",
    "    plt.plot(df_tf2['DATE'], df_tf2[x1], label=f'{x1} Projection', linestyle='--')\n",
    "    plt.plot(df_tf2['DATE'], df_tf2[x2], label=f'{x2} Projection', linestyle='--')\n",
    "    \n",
    "    plt.plot(df_tf1['DATE'], df_tf1[x1], label=x1)\n",
    "    plt.plot(df_tf1['DATE'], df_tf1[x2], label=x2)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set a tick for every day\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    \n",
    "    # plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.tight_layout()  # This helps prevent the rotated labels from being cut off\n",
    "    plt.show()\n",
    "    \n",
    "def plot_time_frame_year_x1(year_start, year_end, df1, df2, x1):\n",
    "    df_tf1 = df1[(df1['DATE'].dt.year >= year_start) & (df1['DATE'].dt.year <= year_end)]\n",
    "    \n",
    "    df_tf2 = df2[(df2['DATE'].dt.year >= year_start) & (df2['DATE'].dt.year <= year_end)]\n",
    "    \n",
    "    plt.plot(df_tf2['DATE'], df_tf2[x1], label=f'{x1} Projection', linestyle='--')\n",
    "    \n",
    "    plt.plot(df_tf1['DATE'], df_tf1[x1], label=x1)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set a tick for every day\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.tight_layout()  # This helps prevent the rotated labels from being cut off\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_df['DATE'] = pd.to_datetime(original_df['DATE'])\n",
    "\n",
    "plot_time_frame_month(2025, 2025, 2, 4, original_df, unnorm_df, features_to_pred[0], features_to_pred[0])\n",
    "# plot_time_frame_year_x1(2000, 2025,original_df, unnorm_df, features_to_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
